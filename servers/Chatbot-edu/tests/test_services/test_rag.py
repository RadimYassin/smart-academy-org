import pytest
from unittest.mock import MagicMock, patch
from services.rag import ask_question
from core.config import settings

@pytest.fixture
def mock_vectorstore():
    """
    Mock the FAISS vectorstore and its search method.
    """
    vs = MagicMock()
    # Mock search results
    doc1 = MagicMock()
    doc1.page_content = "This is a test content from a course."
    doc1.metadata = {"source_file": "course1.pdf", "page": 10}
    
    # Return a list of docs
    vs.similarity_search.return_value = [doc1]
    return vs

@patch("services.rag.load_vectorstore")
@patch("langchain_openai.ChatOpenAI") # Patch the actual source class because of local imports
def test_ask_question_logic(mock_chat_openai, mock_load_vs, mock_vectorstore):
    """
    Test the ask_question business logic.
    We mock the vectorstore loading, the similarity search, and the LLM generation.
    """
    # Arrange
    # 1. Setup VectorStore mock
    mock_load_vs.return_value = mock_vectorstore
    
    # 2. Setup LLM mock
    mock_llm_instance = mock_chat_openai.return_value
    mock_llm_response = MagicMock()
    mock_llm_response.content = "This is the answer generated by AI."
    # The invoke method returns the response object
    mock_llm_instance.invoke.return_value = mock_llm_response
    
    # 3. Force settings to use OpenAI
    with patch("services.rag.settings") as mock_settings_ref:
        mock_settings_ref.llm_provider = "openai"
        mock_settings_ref.openai_model = "gpt-4-test"
        mock_settings_ref.openai_api_key = "fake-key"
        mock_settings_ref.openai_temperature = 0.7
        mock_settings_ref.retrieval_top_k = 4
        
        # Act
        result = ask_question("How does this work?")
        
        # Assert
        # Check if vectorstore was loaded
        mock_load_vs.assert_called_once()
        
        # Check if search was called
        mock_vectorstore.similarity_search.assert_called_with("How does this work?", k=4)
        
        # Check if LLM was invoked
        mock_chat_openai.assert_called()
        mock_llm_instance.invoke.assert_called()
        
        # Validate result structure
        assert result["answer"] == "This is the answer generated by AI."
        assert result["num_sources"] == 1
        assert result["sources"][0]["source_file"] == "course1.pdf"

@patch("services.rag.load_vectorstore")
def test_ask_question_no_docs_found(mock_load_vs, mock_vectorstore):
    """
    Test behavior when no documents are found.
    """
    # Arrange
    mock_load_vs.return_value = mock_vectorstore
    mock_vectorstore.similarity_search.return_value = [] # Empty list
    
    with patch("langchain_openai.ChatOpenAI") as mock_chat_openai:
        with patch("services.rag.settings") as mock_settings_ref:
            mock_settings_ref.llm_provider = "openai"
            mock_settings_ref.openai_api_key = "fake-key"
            mock_settings_ref.openai_temperature = 0.7
            
            mock_llm_instance = mock_chat_openai.return_value
            # Explicitly mock invoke returning an object with .content
            mock_llm_response = MagicMock()
            mock_llm_response.content = "I don't know."
            mock_llm_instance.invoke.return_value = mock_llm_response
            
            # Act
            result = ask_question("Unknown thing")
            
            # Assert
            assert result["num_sources"] == 0
            assert result["answer"] == "I don't know."
