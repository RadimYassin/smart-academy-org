"""
Router pour les interactions chat avec les √©tudiants
Endpoint POST /ask pour poser des questions
"""

from fastapi import APIRouter, HTTPException, status, File, UploadFile, Form
from typing import Optional
from app.models import QuestionRequest, AnswerResponse
from services.rag import ask_question
from services.audio_transcription import transcribe_audio
from services.image_processing import process_image_with_vision
import logging
import os
import base64

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/chat",
    tags=["Chat"],
    responses={404: {"description": "Not found"}}
)


@router.post(
    "/ask",
    response_model=AnswerResponse,
    status_code=status.HTTP_200_OK,
    summary="Poser une question √† l'assistant p√©dagogique",
    description="""
    Permet √† un √©tudiant de poser une question sur les cours.
    L'assistant utilise RAG pour chercher dans les documents vectoris√©s
    et r√©pond selon une approche socratique (p√©dagogique).
    
    **Exemple de question:**
    - "Qu'est-ce qu'une classe en Python ?"
    - "Comment fonctionne l'h√©ritage en Java ?"
    - "Explique-moi les boucles for"
    """
)
async def ask(
    request: QuestionRequest
) -> AnswerResponse:
    """
    Endpoint pour poser une question
    
    Args:
        request: QuestionRequest contenant la question
        
    Returns:
        AnswerResponse: R√©ponse avec answer et sources
        
    Raises:
        HTTPException: Si l'index FAISS n'est pas trouv√© ou erreur interne
    """
    try:
        # Valider que la question n'est pas vide
        if not request.question.strip():
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="La question ne peut pas √™tre vide"
            )
        
        # Log question
        logger.info(f"üì® Question received: {request.question[:80]}...")
        
        # Appeler le moteur RAG
        result = ask_question(request.question)
        
        # Convertir en mod√®le Pydantic
        response = AnswerResponse(**result)
        
        logger.info(f"‚úÖ R√©ponse envoy√©e ({response.num_sources} sources)")
        return response
        
    except FileNotFoundError as e:
        logger.error(f"‚ùå Index FAISS non trouv√©: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="L'index de recherche n'est pas disponible. Veuillez lancer l'ingestion d'abord (POST /admin/ingest)"
        )
    
    except ValueError as e:
        logger.error(f"‚ùå Erreur de validation: {str(e)}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    
    except Exception as e:
        logger.error(f"‚ùå Erreur interne: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors du traitement de la question: {str(e)}"
        )


@router.post(
    "/audio",
    status_code=status.HTTP_200_OK,
    summary="Traiter un fichier audio",
    description="""
    Traite un fichier audio envoy√© par l'utilisateur.
    Si une question est fournie, elle est utilis√©e directement.
    Sinon, une question par d√©faut est utilis√©e (l'utilisateur peut transcrire l'audio c√¥t√© client).
    
    **Note**: La transcription audio c√¥t√© serveur n√©cessite des d√©pendances optionnelles.
    Pour l'instant, utilisez le param√®tre 'question' pour envoyer la transcription.
    """
)
async def process_audio(
    audio: UploadFile = File(...),
    question: Optional[str] = Form(None)
) -> dict:
    """
    Endpoint pour traiter un fichier audio
    
    Args:
        audio: Fichier audio (WAV, MP3, M4A, etc.)
        question: Question texte optionnelle (si fournie, utilis√©e directement)
        
    Returns:
        dict: R√©ponse avec transcription, answer, sources, et model_used
    """
    try:
        # Valider le fichier audio
        if not audio.filename:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Fichier audio requis"
            )
        
        # Sauvegarder temporairement l'audio
        temp_audio_path = f"temp_audio_{os.urandom(8).hex()}_{audio.filename}"
        try:
            with open(temp_audio_path, "wb") as f:
                content = await audio.read()
                f.write(content)
            
            logger.info(f"üìÅ Audio re√ßu: {audio.filename} ({len(content)} bytes)")
            
            # Transcrire l'audio avec Whisper
            transcription = None
            try:
                logger.info("üé§ D√©but de la transcription avec Whisper...")
                transcription = transcribe_audio(temp_audio_path, language="fr")
                logger.info(f"‚úÖ Transcription r√©ussie: {transcription[:100]}...")
            except Exception as e:
                logger.error(f"‚ùå Erreur de transcription: {str(e)}")
                # Si la transcription √©choue, utiliser la question fournie ou une question par d√©faut
                if question and question.strip():
                    transcription = question.strip()
                    logger.info("‚ö†Ô∏è  Utilisation de la question fournie comme transcription")
                else:
                    transcription = "Audio message (transcription not available)"
                    logger.warning("‚ö†Ô∏è  Transcription √©chou√©e et aucune question fournie")
            
            # Utiliser la transcription comme question
            user_question = transcription if transcription and transcription.strip() else "Please analyze this audio message"
            
            # Obtenir la r√©ponse du chatbot
            result = ask_question(user_question)
            
            # Construire la r√©ponse (format compatible avec AudioProcessingResponse)
            response_data = {
                "transcription": transcription if transcription else "Audio message (transcription not available)",
                "answer": result.get('answer', ''),
                "audio_url": "",  # Pas de g√©n√©ration audio pour l'instant (n√©cessite gTTS)
                "sources": result.get('sources', []),
                "model_used": result.get('model_used', 'unknown'),
                "num_sources": result.get('num_sources', 0)
            }
            
            logger.info(f"‚úÖ Audio trait√© avec succ√®s: {len(response_data['answer'])} caract√®res")
            
            return response_data
            
        finally:
            # Nettoyer le fichier temporaire
            if os.path.exists(temp_audio_path):
                try:
                    os.remove(temp_audio_path)
                    logger.info(f"üóëÔ∏è  Fichier temporaire supprim√©: {temp_audio_path}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Impossible de supprimer le fichier temporaire: {e}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du traitement audio: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors du traitement audio: {str(e)}"
        )


@router.post(
    "/image",
    status_code=status.HTTP_200_OK,
    summary="Traiter une image",
    description="""
    Traite une image envoy√©e par l'utilisateur avec OpenAI Vision API.
    L'image est analys√©e et une description est g√©n√©r√©e.
    Si une question est fournie, le syst√®me utilise RAG pour r√©pondre en se basant sur les cours.
    """
)
async def process_image(
    image: UploadFile = File(...),
    question: Optional[str] = Form(None)
) -> dict:
    """
    Endpoint pour traiter une image
    
    Args:
        image: Fichier image (JPG, PNG, GIF, WEBP)
        question: Question optionnelle de l'utilisateur
        
    Returns:
        dict: R√©ponse avec description, answer, sources, et model_used
    """
    try:
        # Valider le fichier image
        if not image.filename:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Fichier image requis"
            )
        
        # V√©rifier le type de fichier
        allowed_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
        file_ext = os.path.splitext(image.filename)[1].lower()
        if file_ext not in allowed_extensions:
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail=f"Format d'image non support√©. Formats accept√©s: {', '.join(allowed_extensions)}"
            )
        
        # Sauvegarder temporairement l'image
        temp_image_path = f"temp_image_{os.urandom(8).hex()}{file_ext}"
        try:
            with open(temp_image_path, "wb") as f:
                content = await image.read()
                f.write(content)
            
            logger.info(f"üñºÔ∏è  Image re√ßue: {image.filename} ({len(content)} bytes)")
            
            # Traiter l'image avec Vision API
            result = process_image_with_vision(temp_image_path, question)
            
            # Construire la r√©ponse
            response_data = {
                "image_description": result.get('image_description', ''),
                "answer": result.get('answer', ''),
                "sources": result.get('sources', []),
                "model_used": result.get('model_used', 'unknown'),
                "num_sources": result.get('num_sources', 0)
            }
            
            logger.info(f"‚úÖ Image trait√©e avec succ√®s: {len(response_data['answer'])} caract√®res")
            
            return response_data
            
        finally:
            # Nettoyer le fichier temporaire
            if os.path.exists(temp_image_path):
                try:
                    os.remove(temp_image_path)
                    logger.info(f"üóëÔ∏è  Fichier temporaire supprim√©: {temp_image_path}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è  Impossible de supprimer le fichier temporaire: {e}")
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du traitement d'image: {str(e)}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors du traitement d'image: {str(e)}"
        )
