# Guide d'Installation et Configuration - Infrastructure EduPath-MS

Ce guide explique comment installer et configurer **PostgreSQL**, **MLflow** et **Airflow** pour le projet EduPath-MS.

---

## ğŸ“‹ PrÃ©requis

- Python 3.8+
- Docker et Docker Compose (recommandÃ©)
- OU PostgreSQL installÃ© localement

---

## ğŸš€ Option 1: DÃ©ploiement avec Docker (RECOMMANDÃ‰)

### Ã‰tape 1: DÃ©marrage des services

```bash
# DÃ©marrer tous les services (PostgreSQL + MLflow + Airflow)
docker-compose up -d

# VÃ©rifier que tout fonctionne
docker-compose ps
```

Les services seront disponibles sur:
- **PostgreSQL**: `localhost:5432`
- **MLflow UI**: http://localhost:5000
- **Airflow UI**: http://localhost:8080 (admin/admin)

### Ã‰tape 2: Initialiser la base de donnÃ©es

```bash
# CrÃ©er les tables
python scripts/init_db.py
```

### Ã‰tape 3: Configurer les variables d'environnement

CrÃ©ez un fichier `.env`:
```bash
# Copier le template
cp .env.example .env

# Ã‰diter avec vos valeurs
DATABASE_URL=postgresql://edupath_user:edupath_password@localhost:5432/edupath_db
MLFLOW_TRACKING_URI=http://localhost:5000
USE_DATABASE=true
OPENAI_API_KEY=sk-your-key-here
```

### Ã‰tape 4: ExÃ©cuter le pipeline

**Mode Manuel**:
```bash
python run_pipeline.py
```

**Mode Airflow**:
1. Aller sur http://localhost:8080
2. Login: admin/admin
3. Activer le DAG `edupath_ms_pipeline`
4. Cliquer sur "Trigger DAG"

---

## ğŸ› ï¸ Option 2: Installation Locale (Sans Docker)

### Ã‰tape 1: Installer PostgreSQL

**Windows**:
1. TÃ©lÃ©charger depuis https://www.postgresql.org/download/windows/
2. Installer avec les paramÃ¨tres par dÃ©faut

**MacOS**:
```bash
brew install postgresql
brew services start postgresql
```

**Linux (Ubuntu)**:
```bash
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql
```

### Ã‰tape 2: CrÃ©er l'utilisateur et la base de donnÃ©es

```bash
# Se connecter Ã  PostgreSQL
sudo -u postgres psql

# Dans psql:
CREATE USER edupath_user WITH PASSWORD 'edupath_password';
CREATE DATABASE edupath_db OWNER edupath_user;
GRANT ALL PRIVILEGES ON DATABASE edupath_db TO edupath_user;
\q
```

### Ã‰tape 3: Installer MLflow

```bash
pip install mlflow

# DÃ©marrer le serveur MLflow
mlflow server --backend-store-uri postgresql://edupath_user:edupath_password@localhost/edupath_db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000
```

AccÃ©der Ã  l'interface: http://localhost:5000

### Ã‰tape 4: Installer Airflow

```bash
# Installer Airflow
pip install apache-airflow

# Initialiser la base de donnÃ©es Airflow
export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql://edupath_user:edupath_password@localhost/edupath_db
airflow db init

# CrÃ©er un utilisateur admin
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@edupath.com \
    --password admin

# DÃ©marrer Airflow webserver et scheduler
airflow webserver --port 8080 &
airflow scheduler &
```

AccÃ©der Ã  l'interface: http://localhost:8080

### Ã‰tape 5: Configuration

CrÃ©er `.env`:
```bash
DATABASE_URL=postgresql://edupath_user:edupath_password@localhost:5432/edupath_db
MLFLOW_TRACKING_URI=http://localhost:5000
USE_DATABASE=true
OPENAI_API_KEY=sk-your-key-here
```

Initialiser la base:
```bash
python scripts/init_db.py
```

---

## ğŸ“Š Utilisation

### Mode CSV (Sans PostgreSQL)

Par dÃ©faut, le systÃ¨me fonctionne en mode CSV:

```bash
# Dans .env:
USE_DATABASE=false

# ExÃ©cuter
python run_pipeline.py
```

### Mode PostgreSQL

Activez PostgreSQL dans `.env`:

```bash
# Dans .env:
USE_DATABASE=true

# ExÃ©cuter
python run_pipeline.py
```

Les donnÃ©es seront stockÃ©es dans PostgreSQL au lieu de CSV.

### MLflow Tracking

Quand MLflow est configurÃ©, les expÃ©riences sont automatiquement trackÃ©es:

```bash
# Voir les expÃ©riences
mlflow ui  # Ouvrir http://localhost:5000
```

### Airflow Orchestration

Le DAG `edupath_ms_pipeline` orchestre automatiquement:
1. **load_data**: Chargement des donnÃ©es
2. **prepa_data**: Nettoyage (PrepaData)
3. **student_profiler**: Clustering (StudentProfiler)
4. **path_predictor**: PrÃ©diction (PathPredictor) avec MLflow
5. **reco_builder**: Recommandations (RecoBuilder)

**ExÃ©cution manuelle**:
```bash
airflow dags test edupath_ms_pipeline
```

**ExÃ©cution programmÃ©e**:
- Schedule: `@daily` (1x par jour)
- Modifiable dans `airflow/dags/edupath_pipeline.py`

---

## ğŸ§ª Tests

### VÃ©rifier PostgreSQL

```bash
# Test de connexion
python -c "from src.database import init_db; init_db()"
```

### VÃ©rifier MLflow

```bash
# Test
python -c "from src.mlflow_config import init_mlflow; init_mlflow()"
```

### VÃ©rifier Airflow

```bash
# Lister les DAGs
airflow dags list

# Devrait afficher: edupath_ms_pipeline
```

---

## ğŸ”§ DÃ©pannage

### PostgreSQL: "Connection refused"

- VÃ©rifiez que PostgreSQL est dÃ©marrÃ©
- VÃ©rifiez le port (5432) n'est pas utilisÃ©
- VÃ©rifiez DATABASE_URL dans .env

### MLflow: Erreur de connexion

- DÃ©marrez le serveur: `mlflow server ...`
- VÃ©rifiez MLFLOW_TRACKING_URI dans .env

### Airflow: DAG non visible

- VÃ©rifiez que le fichier DAG est dans `airflow/dags/`
- RedÃ©marrez le scheduler: `airflow scheduler`
- VÃ©rifiez les logs: `airflow/logs/`

---

## ğŸ“Œ Architecture Finale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Airflow     â”‚  Orchestration
â”‚  (8080)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pipeline    â”‚  4 Microservices
â”‚  Python      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL   â”‚  MLflow  â”‚
â”‚  (5432)       â”‚  (5000)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist de DÃ©ploiement

- [ ] PostgreSQL installÃ© et dÃ©marrÃ©
- [ ] Base de donnÃ©es `edupath_db` crÃ©Ã©e
- [ ] Tables initialisÃ©es (`python scripts/init_db.py`)
- [ ] MLflow serveur dÃ©marrÃ©
- [ ] Airflow webserver + scheduler dÃ©marrÃ©s
- [ ] Fichier `.env` configurÃ©
- [ ] DÃ©pendances installÃ©es (`pip install -r requirements.txt`)
- [ ] DAG visible dans Airflow UI
- [ ] Test d'exÃ©cution rÃ©ussi

---

**Vous Ãªtes prÃªt ! Le systÃ¨me est maintenant 100% conforme au cahier des charges.** ğŸ‰
