"""
DÃ‰MONSTRATION DU MODÃˆLE XGBOOST - EduPath-MS
=============================================

Ce script montre comment le modÃ¨le fonctionne avec des exemples concrets.
"""

import pickle
import pandas as pd
import numpy as np
from src.config import *

print("="*70)
print("ðŸŽ“ DÃ‰MONSTRATION DU MODÃˆLE EDUPATH-MS")
print("="*70)

# ============================================================================
# 1. CHARGER LE MODÃˆLE ENTRAÃŽNÃ‰
# ============================================================================
print("\nðŸ“¦ Chargement du modÃ¨le XGBoost entraÃ®nÃ©...")
with open(XGBOOST_MODEL, 'rb') as f:
    model = pickle.load(f)
print("âœ“ ModÃ¨le chargÃ© avec succÃ¨s!")

# ============================================================================
# 2. CHARGER LES DONNÃ‰ES NETTOYÃ‰ES POUR RÃ‰FÃ‰RENCE
# ============================================================================
print("\nðŸ“‚ Chargement des donnÃ©es pour rÃ©fÃ©rence...")
df = pd.read_csv(CLEANED_DATA)

# Encoder Major comme dans le pipeline
from sklearn.preprocessing import LabelEncoder
le_major = LabelEncoder()
df['Major_Encoded'] = le_major.fit_transform(df['Major'].fillna('Unknown'))

print(f"âœ“ {len(df)} enregistrements chargÃ©s")

# Afficher quelques statistiques
print(f"\nðŸ“Š Statistiques des donnÃ©es:")
print(f"  - MatiÃ¨res uniques: {df['Subject_Encoded'].nunique()}")
print(f"  - FiliÃ¨res: {df['Major'].nunique()}")
print(f"  - Taux d'Ã©chec global: {df['is_fail'].mean()*100:.2f}%")

# ============================================================================
# 3. EXEMPLES DE PRÃ‰DICTION - CAS RÃ‰ELS
# ============================================================================
print("\n" + "="*70)
print("ðŸ”® EXEMPLES DE PRÃ‰DICTIONS")
print("="*70)

# Prendre quelques exemples rÃ©els du dataset
sample_students = df.sample(n=5, random_state=42)

print("\nðŸ“ Features utilisÃ©es par le modÃ¨le:")
feature_names = ['Subject_Encoded', 'Semester', 'Practical', 'Theoretical', 'Total', 'MajorYear', 'Major_Encoded']
print(f"  {', '.join(feature_names)}")

print("\n" + "-"*70)
for idx, (i, student) in enumerate(sample_students.iterrows(), 1):
    # PrÃ©parer les features
    features = student[feature_names].values.reshape(1, -1)
    
    # PrÃ©diction
    prediction = model.predict(features)[0]
    probability = model.predict_proba(features)[0]
    
    # RÃ©alitÃ©
    actual = student['is_fail']
    
    # Afficher
    print(f"\nðŸŽ“ Ã‰TUDIANT {idx}:")
    print(f"  MatiÃ¨re: {student['Subject']}")
    print(f"  Semestre: {int(student['Semester'])}")
    print(f"  Note Pratique: {student['Practical']:.1f}")
    print(f"  Note ThÃ©orique: {student['Theoretical']:.1f}")
    print(f"  Total: {student['Total']:.1f}")
    print(f"  FiliÃ¨re: {student['Major']}")
    
    # PrÃ©diction vs RÃ©alitÃ©
    pred_label = "âŒ Ã‰CHEC" if prediction == 1 else "âœ… RÃ‰USSITE"
    actual_label = "âŒ Ã‰CHEC" if actual == 1 else "âœ… RÃ‰USSITE"
    correct = "âœ“ CORRECT" if prediction == actual else "âœ— INCORRECT"
    
    print(f"\n  ðŸ”® PRÃ‰DICTION: {pred_label}")
    print(f"     ProbabilitÃ© d'Ã©chec: {probability[1]*100:.2f}%")
    print(f"     ProbabilitÃ© de rÃ©ussite: {probability[0]*100:.2f}%")
    print(f"  ðŸ“Š RÃ‰ALITÃ‰: {actual_label}")
    print(f"  {correct}")
    print("-"*70)

# ============================================================================
# 4. TESTER DIFFÃ‰RENTS SCÃ‰NARIOS
# ============================================================================
print("\n" + "="*70)
print("ðŸ§ª TESTS DE SCÃ‰NARIOS HYPOTHÃ‰TIQUES")
print("="*70)

# Encoder une filiÃ¨re pour le test (prenons la moyenne)
avg_major_encoded = df['Major_Encoded'].mean()

scenarios = [
    {
        'nom': "Ã‰tudiant Excellent",
        'features': [10, 2, 28, 65, 93, 1, avg_major_encoded],
        'description': "Notes Ã©levÃ©es (Pratique: 28/30, ThÃ©orique: 65/70)"
    },
    {
        'nom': "Ã‰tudiant Moyen",
        'features': [15, 2, 15, 45, 60, 1, avg_major_encoded],
        'description': "Notes moyennes (Pratique: 15/30, ThÃ©orique: 45/70)"
    },
    {
        'nom': "Ã‰tudiant en DifficultÃ©",
        'features': [20, 2, 8, 20, 28, 1, avg_major_encoded],
        'description': "Notes faibles (Pratique: 8/30, ThÃ©orique: 20/70)"
    },
    {
        'nom': "Ã‰tudiant Absent",
        'features': [5, 1, 0, 0, 0, 1, avg_major_encoded],
        'description': "Absence totale (toutes les notes Ã  0)"
    }
]

for scenario in scenarios:
    features = np.array(scenario['features']).reshape(1, -1)
    prediction = model.predict(features)[0]
    probability = model.predict_proba(features)[0]
    
    pred_label = "âŒ Ã‰CHEC" if prediction == 1 else "âœ… RÃ‰USSITE"
    
    print(f"\nðŸ“š ScÃ©nario: {scenario['nom']}")
    print(f"   {scenario['description']}")
    print(f"   ðŸ”® PrÃ©diction: {pred_label}")
    print(f"   ðŸ“Š ProbabilitÃ© d'Ã©chec: {probability[1]*100:.2f}%")
    print(f"   ðŸ“Š ProbabilitÃ© de rÃ©ussite: {probability[0]*100:.2f}%")

# ============================================================================
# 5. IMPORTANCE DES FEATURES
# ============================================================================
print("\n" + "="*70)
print("ðŸ“Š IMPORTANCE DES FACTEURS DE PRÃ‰DICTION")
print("="*70)

feature_importance = model.feature_importances_
importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': feature_importance
}).sort_values('Importance', ascending=False)

print("\nFacteurs classÃ©s par importance (du plus au moins important):")
for idx, row in importance_df.iterrows():
    bar_length = int(row['Importance'] * 50)
    bar = 'â–ˆ' * bar_length
    print(f"  {row['Feature']:20s} | {bar} {row['Importance']:.4f}")

# ============================================================================
# 6. STATISTIQUES DU MODÃˆLE
# ============================================================================
print("\n" + "="*70)
print("ðŸ“ˆ STATISTIQUES DU MODÃˆLE")
print("="*70)

# Faire des prÃ©dictions sur l'ensemble du dataset
all_features = df[feature_names].fillna(0)
all_predictions = model.predict(all_features)
all_actuals = df['is_fail']

# Calculer l'accuracy
accuracy = (all_predictions == all_actuals).mean()
correct_failures = ((all_predictions == 1) & (all_actuals == 1)).sum()
total_failures = (all_actuals == 1).sum()
recall_failure = correct_failures / total_failures if total_failures > 0 else 0

print(f"\nðŸŽ¯ Performance globale:")
print(f"  - Accuracy: {accuracy*100:.2f}%")
print(f"  - Ã‰checs correctement dÃ©tectÃ©s: {correct_failures}/{total_failures} ({recall_failure*100:.2f}%)")
print(f"  - Total de prÃ©dictions: {len(all_predictions):,}")

# ============================================================================
# 7. CONCLUSION
# ============================================================================
print("\n" + "="*70)
print("âœ… DÃ‰MONSTRATION TERMINÃ‰E")
print("="*70)
print("\nðŸ’¡ Points clÃ©s:")
print("  1. Le modÃ¨le prend en compte 7 features (matiÃ¨re, notes, semestre, etc.)")
print("  2. Il prÃ©dit Ã‰CHEC ou RÃ‰USSITE avec une probabilitÃ© associÃ©e")
print(f"  3. Accuracy globale: {accuracy*100:.2f}%")
print("  4. Le facteur le plus important est probablement la note 'Total'")
print("\nðŸš€ Le modÃ¨le est prÃªt Ã  Ãªtre utilisÃ© en production!")
print("="*70 + "\n")
